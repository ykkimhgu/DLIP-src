{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0yKMyUBeU3P"
   },
   "source": [
    "# **DLIP Tutorial - PyTorch**\n",
    "\n",
    "## MNIST Classification using PyTorch\n",
    "Y.-K. Kim\n",
    "(updated 2024. 4. 29)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For CoLab Usage:\n",
    "\n",
    "1. Download this notebook\n",
    "2. Then, open in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO152O2SzILP"
   },
   "source": [
    "The purpose of this tutorial is to learn how to build a simple Multi-Layer Percentron (MLP or ANN) for classification of handwritting digits (MNIST)\n",
    "\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lHqSoDaeUSs"
   },
   "source": [
    "## Setup Pytorch and Numpy and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:14:54.425674Z",
     "start_time": "2024-04-29T06:14:51.384129Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y228XLuj1215",
    "outputId": "46767815-1b31-4e62-acbd-22cd6fbd870c"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:15:06.327791Z",
     "start_time": "2024-04-29T06:15:06.290513Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shdSXuyuE1rJ",
    "outputId": "4ac19d45-8223-4df7-c1c9-8d91f8d3f0dd"
   },
   "outputs": [],
   "source": [
    "# Select GPU or CPU for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blEBaK0ugMUS"
   },
   "source": [
    "## Prepare Datasets\n",
    "### OpenDataset from TorchVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0odtPtd2bzl"
   },
   "source": [
    "\n",
    "1. Loading OpenDataset (Fashion MNIST) from Pytorch data\n",
    "* ``Dataset``:  stores the samples and their corresponding labels\n",
    "* ``DataLoader`` wraps an iterable around the ``Dataset``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:17:34.426945Z",
     "start_time": "2024-04-29T06:15:20.552576Z"
    },
    "id": "r8PiOEFx2bzn"
   },
   "outputs": [],
   "source": [
    "# Download Dataset from TorchVision MNIST\n",
    "# Once, downloaded locally, it does not download again.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),   #converts 0~255 value to 0~1 value.\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uel8Ptvr2bzo"
   },
   "source": [
    "2. Use  ``DataLoader`` to  make dataset iterable.\n",
    "* supports automatic batching, sampling, shuffling and multiprocess data loading.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:17:48.557053Z",
     "start_time": "2024-04-29T06:17:48.544047Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdFdt1pe2bzo",
    "outputId": "31d160c7-ae30-49bc-c936-b6176ddea0c2"
   },
   "outputs": [],
   "source": [
    "# Create DataLoader with Batch size N\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ7CqtrmG0mp"
   },
   "source": [
    "3. Plot some training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:18:47.995259Z",
     "start_time": "2024-04-29T06:18:47.751701Z"
    },
    "id": "ccpGGs8dG4dR"
   },
   "outputs": [],
   "source": [
    "# Visualize some Datasets\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 9\n",
    "for index in range(num_of_images):\n",
    "    plt.subplot(3, 3, index+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ground Truth: {}\".format(labels[index]))\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slHZqHyYFZ7p"
   },
   "source": [
    "# Define model\n",
    "\n",
    "create a class that inherits from nn.Module\n",
    "\n",
    "\n",
    "* Define the layers of the network in  __init__ function\n",
    "* Specify Forward network in the **forward function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZw6AmlIk3OD"
   },
   "source": [
    "![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/mlp-mnist.png?raw=1)\n",
    "\n",
    "\n",
    "* Image Input: 1x28x28  image\n",
    "* Flatten into a 1*784 element vector\n",
    "* 1st Layer: linear to 250 dimensions / ReLU\n",
    "* 2nd Layer: linear to 100 dim / ReLU\n",
    "* 3rd Layer: linear to 10 dim / log SoftMax\n",
    "* Output:  1x10\n",
    "\n",
    "Actication function: ReLU\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "\n",
    "1) nn.Linear(InputDim, OutputDim)\n",
    "\n",
    "\n",
    "2) x.view( )\n",
    "* Similar to  NumPy Reshape(). /// [batch size, height * width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:19:02.089866Z",
     "start_time": "2024-04-29T06:19:01.984741Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfyWWHhon11D",
    "outputId": "cd9f866c-ea93-4834-9dbe-d378bd6d3e7a"
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(28*28, 250)\n",
    "        self.linear2 = nn.Linear(250, 100)\n",
    "        self.linear3 = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        x= F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        y_pred = F.log_softmax(self.linear3(x))\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = MLP().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fDrJCT_esSf"
   },
   "source": [
    "## Weight Initialization\n",
    " In Keras, dense layers by default uses “glorot_uniform” random initializer, it is also called Xavier normal initializer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5SxTs1he7Df"
   },
   "source": [
    "# Optimization Setup  \n",
    "\n",
    "### Optmizer function\n",
    " Gradient descent is the common optimisation strategy used in neural networks. Many of the variants and advanced optimisation functions now are available,\n",
    "  \n",
    "- Stochastic Gradient Descent, Adagrade, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "1. Linear regression->Mean Squared Error\n",
    "2. Classification->Cross entropy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:19:11.791904Z",
     "start_time": "2024-04-29T06:19:11.773862Z"
    },
    "id": "be3HOqoeipmU"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZS7b363jAzB"
   },
   "source": [
    "# Train the model\n",
    "### Define train() function\n",
    "Reuse this function in other tutorials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:19:14.791255Z",
     "start_time": "2024-04-29T06:19:14.774222Z"
    },
    "id": "tweilksdivvD"
   },
   "outputs": [],
   "source": [
    "# Train Module\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # Dataset Size\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Model in Training Mode\n",
    "    model.train()\n",
    "\n",
    "    running_loss=0.0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # zero gradients for every batch\n",
    "        optimizer.zero_grad()   \n",
    "\n",
    "        # Compute prediction loss \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation and Update        \n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "\n",
    "        # Print loss for every 100 batch in an epoch\n",
    "        running_loss+=loss.item()\n",
    "        if batch % 100 == 0:\n",
    "            running_loss=running_loss/100\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {running_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            running_loss=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ6lGq6UJPVw"
   },
   "source": [
    "### Train\n",
    "Print training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:19:28.038671Z",
     "start_time": "2024-04-29T06:19:20.111572Z"
    },
    "id": "5--jTU4tJS0Y"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9JJWT1A8zvX"
   },
   "source": [
    "# Test the model  ``eval()``\n",
    "\n",
    "### Define **test()** function\n",
    "Using ``eval()`` for test. Evaluate mode로 전환\n",
    "This function can be reused in other tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:19:35.300215Z",
     "start_time": "2024-04-29T06:19:35.288213Z"
    },
    "id": "xvmC5oFs72SC"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    # Dataset Size\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Batch Size\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # Model in Evaluation Mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, correctN = 0, 0\n",
    "    \n",
    "    # Disable grad() computation to reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Compute average prediction loss \n",
    "            pred = model(X)            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # Predict Label\n",
    "            y_pred=pred.argmax(1);\n",
    "            correctN += (y_pred == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correctN /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correctN):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc_uKTg685fR"
   },
   "source": [
    "### Test\n",
    "Print test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:19:42.931521Z",
     "start_time": "2024-04-29T06:19:41.487939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AyUVhP58U4W",
    "outputId": "0a1f3ca4-f6fa-4cb0-988b-f61199c24fd5"
   },
   "outputs": [],
   "source": [
    "test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7reJNX_fMgwG"
   },
   "source": [
    "### Visualize Evaluation Results\n",
    "\n",
    "Select random test images and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:20:01.817535Z",
     "start_time": "2024-04-29T06:20:01.166251Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpVhWXBYMlYh",
    "outputId": "ca332027-e51a-4632-92b9-be0bcfd9be1b"
   },
   "outputs": [],
   "source": [
    "# Get some random test  images // BatchSize at a time\n",
    "dataiter = iter(test_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.size())\n",
    "\n",
    "# Evaluate mode\n",
    "# Prediction of some sample images \n",
    "images, labels = images.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(images)\n",
    "    _, predicted = torch.max(pred.data, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8Lnx8mKRo_c"
   },
   "source": [
    "Plot some test image results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:20:10.469072Z",
     "start_time": "2024-04-29T06:20:10.272105Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "PUfby6DlRoXW",
    "outputId": "2dd5d6ea-1c9b-4f6e-e7ce-550d6fcef775"
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "figure = plt.figure()\n",
    "num_of_images = 9\n",
    "for index in range(num_of_images):\n",
    "    plt.subplot(3, 3, index+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Predicted: {}\".format(predicted[index].item()))\n",
    "    plt.imshow(images[index].cpu().numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Y-krgJinAp"
   },
   "source": [
    "### Saving Models\n",
    "(Option 1) Save Model with Shapes\n",
    "* save the structure of this class together with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:20:15.615847Z",
     "start_time": "2024-04-29T06:20:15.599763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f9tXsz9KxDx",
    "outputId": "a4319e72-c21c-4a3f-9600-fa08c662fa09"
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"MNIST_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-K0cBwkK1OI"
   },
   "source": [
    "(Option 2) Save Model Weight as  state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:20:18.376957Z",
     "start_time": "2024-04-29T06:20:18.368946Z"
    },
    "id": "69luqmxDgkqK"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"MNIST_model2.pth\")\n",
    "print(\"Saved PyTorch Model State\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model\n",
    "\n",
    "(Option 1) Loading a model with structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"MNIST_model.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Option 2) Loading a model includes re-creating the model structure and loading the state dictionary into it.\n",
    "\n",
    "* Need to `import` or define the Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(28*28, 250)\n",
    "        self.linear2 = nn.Linear(250, 100)\n",
    "        self.linear3 = nn.Linear(100, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        x= F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        y_pred = F.log_softmax(self.linear3(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MLP().to(device)\n",
    "print(model2)\n",
    "model2.load_state_dict(torch.load('MNIST_model2.pth'))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test \n",
    "Print test data accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize test results\n",
    "\n",
    "Select random test images and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some random test  images // BatchSize at a time\n",
    "dataiter = iter(test_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.size())\n",
    "\n",
    "# Evaluate mode\n",
    "# Prediction of some sample images \n",
    "images, labels = images.to(device), labels.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(images)\n",
    "    _, predicted = torch.max(pred.data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some test image results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 9\n",
    "for index in range(num_of_images):\n",
    "    plt.subplot(3, 3, index+1)\n",
    "    plt.axis('off')    \n",
    "    plt.title(\"Predicted: {}\".format(predicted[index].item()))\n",
    "    plt.imshow(images[index].cpu().numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBdmu3Z4K3LZ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xi-1ht0d-SbX"
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_irKEtZP9bmB"
   },
   "source": [
    "\n",
    "## Exercise 1\n",
    "Change, activation functions and optimization types for a better output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSVSgxzq-GbI"
   },
   "source": [
    "## Exercise 2\n",
    "Rewrite  the above MLP model as the following.\n",
    "\n",
    "![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mlp_mnist.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial_PyTorch_MNIST_MLP_Part1_Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
