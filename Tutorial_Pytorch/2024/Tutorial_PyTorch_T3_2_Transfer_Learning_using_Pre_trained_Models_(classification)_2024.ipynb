{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA6sxZvU0pU_"
      },
      "source": [
        "# **DLIP Tutorial - PyTorch**\n",
        "# Transfer Learning using Pre-trained Models (Classification)\n",
        "\n",
        "Y.-K. Kim\n",
        "(updated 2024. 5. 9) \n",
        "\n",
        "===================\n",
        "\n",
        "- Part1: inference using pre-trained model\n",
        "\n",
        "- **Part2: Transfer Learning using Pre-trained Models (Classification)**\n",
        "\n",
        " : The purpose of this tutorial is to learn how to **transfer learning** using a pre-trained model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDPCnTHL16ac"
      },
      "source": [
        "In this document we will perform two types of **transfer learning**: \n",
        "- **finetuning**: update all parameters of the pretrained model for our new task\n",
        "- **feature extraction**: only update the final layer weights from which we derive predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For CoLab Usage:\n",
        "\n",
        "1. Download this notebook\n",
        "2. Then, open in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUhurhuXLJn"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "we will download Python modules and image data. \n",
        "- [download modules](https://drive.google.com/file/d/1hjrWkcvBTiI-5yGtWPvsYVdaE7YLNWDo/view?usp=sharing)\n",
        "- [download dataset(ant/bee)](https://drive.google.com/file/d/123qUnqUpSzpnj7BnJjftFClmK6PLRzfA/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml-yjzwy2V0M"
      },
      "source": [
        "![image](https://github.com/ykkimhgu/DLIP_doc/blob/master/.gitbook/assets/dir.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkrQAZxK6_lL",
        "outputId": "b1d7868a-7e17-47ba-f501-473b26064ccf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# from set_parameter_requires_grad import set_parameter_requires_grad\n",
        "from initialize_model import initialize_model\n",
        "from train import train\n",
        "from test import test\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "if torch.cuda.is_available(): print(f'Device name: {torch.cuda.get_device_name(0)}') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuWFu1dRT9ME"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu7t3PHjw7S_"
      },
      "source": [
        "Basically, the classification models provided by torchvision are trained on ImageNet and consist of 1000 output layers.\n",
        "\n",
        "However, in the model for fine-tuning with other datasets, the number of output layers should be different depending on the class.\n",
        "\n",
        "Here, we use the initialize_model() function provided in the [pytorch tutorial](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html) to change the output stage of the model.\n",
        "\n",
        "initialize_model() is a function that helps to initialize the fine-tuning of some models.\n",
        "\n",
        "If the model is not in the function, the output layer information can be known by printing the model with the print() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfAzSQm_7e-3",
        "outputId": "3c5b56ba-f5cc-4efb-af61-ad59fe7ad6d7"
      },
      "outputs": [],
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception*]\n",
        "model_name = \"resnet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# - True(feature extraction): only update the reshaped layer params,\n",
        "# - False(finetuning)       : finetune the whole model, \n",
        "feature_extract = True  \n",
        "\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model_ft, (3,input_size,input_size))\n",
        "\n",
        "print(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStHdh2KUBRC"
      },
      "source": [
        "# Prepare Datasets: hymenoptera_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJN_phYB12sC"
      },
      "source": [
        "Unzip hymenoptera_data.zip to create training data\n",
        "\n",
        "[hymenoptera_data](https://www.kaggle.com/datasets/ajayrana/hymenoptera-data) is a binary (Ants and Bees) classification dataset consisting of a small number of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7WI7GwfUiLm"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "shutil.unpack_archive(\"data/hymenoptera_data.zip\", \"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo08bMfU2lEU"
      },
      "source": [
        "The images in the prepared dataset have different sizes. In order to be used as a learning model, the following process is required.\n",
        "\n",
        "- Assign the images in the folder to training/test data for learning\n",
        "- Same pre-processing as ImageNet data for input of learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83UxwTIIV-0m",
        "outputId": "bbffc756-18b1-4e83-d1f9-c3a2d37b4dfd"
      },
      "outputs": [],
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms \n",
        "#   to the ImageFolder structure\n",
        "data_dir = \"./data/hymenoptera_data\"\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "# Normalized with ImageNet mean and variance\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "training_data = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform['train'])\n",
        "test_data = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform['val'])\n",
        "\n",
        "classes = ['ant', 'bee']\n",
        "print(f\"train dataset length = {len(training_data)}\")\n",
        "print(f\"test  dataset length = {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJR2fBj84oAA"
      },
      "source": [
        "Use DataLoader to make dataset iterable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCHtaMbZUfDA",
        "outputId": "b611f330-1c92-4f28-cbef-c63f06e3af76"
      },
      "outputs": [],
      "source": [
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape} {y.dtype}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYEEjueXfVJI"
      },
      "source": [
        "# Optimization Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCLJEDUs40bd"
      },
      "source": [
        "### Optmizer function \n",
        " Gradient descent is the common optimisation strategy used in neural networks. Many of the variants and advanced optimisation functions now are available, \n",
        "  \n",
        "- Stochastic Gradient Descent, Adagrade, Adam, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RL7WCYp483c"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "- Linear regression->Mean Squared Error\n",
        "- Classification->Cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFqXoS-YIL8I"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_ft.parameters(), lr = 0.001, momentum=0.9,weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4a5N0o7fXth"
      },
      "source": [
        "# Train and Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHjrOqIJWSVK",
        "outputId": "72065072-530a-4c60-fe25-6577337ceacb"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model_ft, loss_fn, optimizer, device, 15)\n",
        "    test(test_dataloader, model_ft, loss_fn, device)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eegwkx0E5Psm"
      },
      "source": [
        "# Visualize test results\n",
        "\n",
        "Select random test images and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "opjyP_xXMAPe",
        "outputId": "d41496a7-d961-4b00-af7c-95e6156539d5"
      },
      "outputs": [],
      "source": [
        "# Get some random test  images // BatchSize at a time\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model_ft(images)\n",
        "    _, predicted = torch.max(pred.data, 1);\n",
        "\n",
        "figure = plt.figure()\n",
        "num_of_images = min(batch_size, 9)\n",
        "\n",
        "for index in range(num_of_images):\n",
        "    plt.subplot(3, 3, index+1)\n",
        "    plt.axis('off')    \n",
        "    plt.title(f\"Ground Truth: {classes[labels[index]]}\")\n",
        "    plt.title(f\"{classes[predicted[index].item()]} (true:{classes[labels[index]]})\")\n",
        "    plt.imshow(np.transpose((images[index] * 0.224  + 0.456).cpu().numpy().squeeze(), (1, 2, 0)))  # 출력을 위한 차원변환 (channels*rows*cols) -> (rows*cols*channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDZa3absBt0Y"
      },
      "source": [
        "Plot heatmap (confusion matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "Z5dB7393NoVK",
        "outputId": "d4741c8b-3cc1-420e-8035-24dc1d85a70a"
      },
      "outputs": [],
      "source": [
        "# Get some random test  images // BatchSize at a time\n",
        "heatmap = pd.DataFrame(data=0,index=classes,columns=classes)\n",
        "\n",
        "for images, labels in test_dataloader:\n",
        "    with torch.no_grad():\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_ft(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            true_label = labels[i].item()\n",
        "            predicted_label = predicted[i].item()\n",
        "            heatmap.iloc[true_label, predicted_label] += 1\n",
        "print(heatmap)\n",
        "_, ax = plt.subplots(figsize=(10, 8))\n",
        "ax = sns.heatmap(heatmap, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adO8bmjm5UcV"
      },
      "source": [
        "# Saving Models\n",
        "* save the structure of this class together with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ren2lazx5WCo"
      },
      "outputs": [],
      "source": [
        "torch.save(model_ft, f\"{model_name}_ft(hymenoptera).pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Tutorial_PyTorch_T3-2_Transfer Learning using Pre-trained Models (classification).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
